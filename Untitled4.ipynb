{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUGTnu8zojAv",
        "outputId": "3253f69c-2044-4485-b8a3-cd0d0656df3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Datasets'...\n",
            "remote: Enumerating objects: 18913, done.\u001b[K\n",
            "remote: Total 18913 (delta 0), reused 0 (delta 0), pack-reused 18913\u001b[K\n",
            "Receiving objects: 100% (18913/18913), 2.21 GiB | 38.72 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (18911/18911), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/naveenkumar12624/Datasets.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwI6GSQZpUYV",
        "outputId": "9d3788c2-7888-4e51-af25-1958c337176d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "d8JF2iH2qJy_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = '/content/Datasets'\n"
      ],
      "metadata": {
        "id": "W2qp-WgTqRKw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128, 128)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "9pq1XgIQrIaY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale pixel values to the range [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images within Â±20 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift the width of images\n",
        "    height_shift_range=0.2,  # Randomly shift the height of images\n",
        "    shear_range=0.2,  # Apply shear transformation\n",
        "    zoom_range=0.2,  # Randomly zoom into images\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    validation_split=0.2  # Split data into training and validation sets\n",
        ")\n",
        "\n",
        "# Create separate data generators for training and validation\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    image_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Assuming skin diseases are classified\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    image_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Define and compile the deep learning model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
        "batch_size = 64\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7I1Tfi3rIdz",
        "outputId": "fda099e0-c8e9-4f5b-dcf1-fd04447534e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15133 images belonging to 18 classes.\n",
            "Found 3778 images belonging to 18 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 18  # Adjust the number of epochs as needed\n",
        "history = model.fit(train_generator, validation_data=validation_generator, epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djWF_L2grjWX",
        "outputId": "65294684-02e7-4ccf-8c77-3a564293150b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "473/473 [==============================] - 256s 515ms/step - loss: 0.9919 - accuracy: 0.7118 - val_loss: 1.0451 - val_accuracy: 0.6755\n",
            "Epoch 2/18\n",
            "473/473 [==============================] - 235s 497ms/step - loss: 0.8765 - accuracy: 0.7246 - val_loss: 0.9898 - val_accuracy: 0.6948\n",
            "Epoch 3/18\n",
            "473/473 [==============================] - 243s 513ms/step - loss: 0.8293 - accuracy: 0.7327 - val_loss: 0.9896 - val_accuracy: 0.6887\n",
            "Epoch 4/18\n",
            "473/473 [==============================] - 259s 548ms/step - loss: 0.7891 - accuracy: 0.7439 - val_loss: 0.9852 - val_accuracy: 0.6935\n",
            "Epoch 5/18\n",
            "171/473 [=========>....................] - ETA: 2:17 - loss: 0.7899 - accuracy: 0.7398"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation metrics\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wS1rcB7RrtJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}